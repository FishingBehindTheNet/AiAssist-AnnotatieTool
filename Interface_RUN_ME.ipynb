{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ai assisted annoteren: de Pijplijn**\n",
    "Dit notebook is gemaakt als een pijplijn voor het annoteren en het maken van modellen voor het gebruik in ai assisted annoteren. Momenteel werkt de code alleen voor .jpg en .JPG bestanden. Op verzoek kan deze of andere functies aangepast of uitgebreid worden. Voor vragen, verzoeken of bugs kun je contact opnemen met Sjoerd Barten via de volgende e-mailadressen:\n",
    "* sjoerdrubenbarten@gmail.com\n",
    "* 540256358@has.nl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image Tiler**\n",
    "De Image Tiler is bedoeld om foto's op te delen in gelijke segmenten. Deze stap wordt gebruikt om de data behapbaarder te maken voor het model tijdens het trainen, en voor de gebruiker tijdens het annoteren. De tool genereert gesegmenteerde foto's voor een hele map. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De naam van de segmenten wordt opgebouwd als volgt:\n",
    "\n",
    "* {Naam origineel} _ {X coördinaat hoek links boven} _ {Y coördinaat hoek links boven}.jpg.\n",
    "\n",
    "De segmenten worden opgeslagen onder de volgende locatie:\n",
    "* .\\\\{project}\\data\\\\{naam dataset}\\images\\\n",
    "\n",
    "veder word er in de {naam dataset} map een lege folder voor labels gemaakt als deze nog niet bestaat."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile size\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De tool staat standaard ingesteld op 640px (640px bij 640px: segmenten zijn vierkant), maar kan naar wens aangepast worden. Kleinere segmenten maken het lichter voor de computer om het model te trainen, maar grotere segmenten kunnen zorgen voor een beter model als je objecten groter zijn dan de huidige segmentgrootte of als ze niet in hun geheel op de segmenten staan."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens het segmenteren van een foto is het mogelijk dat een object wordt opgeknipt over twee segmenten heen. Om de gevolgen hiervan te minimaliseren, is de overlapparameter geïntroduceerd. Deze parameter bepaalt hoeveel procent van een segment ook wordt weergegeven op het segment eronder en het segment rechts van dit segment. Op deze manier zijn opgedeelde objecten vaak op een van de twee segmenten alsnog volledig zichtbaar. Wanneer deze waarde naar nul gebracht wordt, is er geen overlap van de segmenten. De waarde staat standaard ingesteld op tien procent, maar kan naar behoefte aangepast worden. Let echter wel op: hoe groter de overlap is, hoe meer segmenten gegenereerd worden.\n",
    "\n",
    "\n",
    "<code style=\"color:red;\">*Een grote overlap kan betekenen dat sommige objecten 2 keer voorkomen. Dit kan leiden tot een groter kans op overfitting.*</code>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d62aa44ebbf4134b26f03b86b14adfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>_________________________________________________________Image Tiler/Cutter____…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Modules.ImageTile import ImageTiler\n",
    "ImageTiler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Annoteren**\n",
    "Dit is de interface voor het annoteren van segmenten. Wanneer bij het opstarten een model geselecteerd wordt, is de AiAssist beschikbaar die annotaties genereert op basis van dit model. Deze annotaties worden na controle toegevoegd aan de map met labels. De tool heeft meerdere interfaces die na elkaar worden weergegeven. Deze worden hieronder kort toegelicht:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model keuze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier selecteer je een project en een model voor de AI assist. Wanneer deze niet worden ingevuld, wordt de tool ingeladen zonder de specifieke functies van het model, zoals \"AiAssist\" of \"genereer opnieuw\". Voorspellingen van een aangegeven model worden opgeslagen onder de projectnaam, wat het verplicht maakt om een project te selecteren wanneer een model wordt geselecteerd."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map locaties\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier selecteer je de mappen waar de foto-segmenten en bijbehorende labels staan. Als je voor het eerst gaat labelen en de segmenten niet zijn gemaakt met de Image Tiler, is het mogelijk dat je nog geen labelmap hebt. In dit geval moet je zelf handmatig een map maken/toewijzen waarin de labels kunnen worden opgeslagen. Als je Image-map veel foto's bevat, kan het selecteren van deze map of onderliggende mappen ervoor zorgen dat de tool tijdelijk bevriest. Dit probleem zou na enkele seconden moeten zijn opgelost. De grootte en hoeveelheid foto's/segmenten in de map bepalen de intensiteit van dit probleem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label controle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier controleer je de labels die gebruikt worden voor het annoteren. Labels kunnen hier naar behoefte worden toegevoegd. De labels worden opgeslagen in het bestand \"Labels.txt\" in de geselecteerde labelmap. Als de spelling of formulering van labels aangepast moet worden, kan dit handmatig in dit bestand worden gedaan. Let er hierbij op dat de labels worden vertaald op basis van hun posities in de lijst. Dit betekent dat het niet verstandig is om de lijst te herordenen of labels toe te voegen (anders dan via de interface) of labels te verwijderen uit de bestaande lijst. Als dit toch wordt gedaan, bestaat de mogelijkheid dat eerder gemaakte annotaties de verkeerde labels weergeven.\n",
    "\n",
    "Bovendien wordt, wanneer een model is geselecteerd, gecontroleerd of het \"Labels.txt\"-bestand gelijk is aan de lijst met labels die tijdens het trainen van het geselecteerde model zijn gebruikt. Als deze niet identiek zijn, worden beide lijsten weergegeven en moet er een keuze worden gemaakt over welke labels verder worden gebruikt. Als de labels van het model worden gekozen, zal het \"Labels.txt\"-bestand worden overschreven met de nieuwe lijst met labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotatie\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze interface is bedoeld voor het maken van daadwerkelijke annotaties. De code controleert of er bij de foto's uit de afbeeldingenmap bijbehorende labels zijn. De foto's met labels worden in alfabetische volgorde aan een lijst toegevoegd, terwijl de rest van de foto's in een willekeurige volgorde aan het einde van de lijst worden geplaatst. De interface toont vervolgens de volgende foto in de lijst die nog geen annotaties heeft.\n",
    "\n",
    "De interface kan worden bediend met de muis via de verschillende weergegeven knoppen. De kaders van de bounding boxes (BBox) kunnen worden getekend door te klikken op de positie van een van de toekomstige hoeken van de nieuwe BBox en deze naar de tegenovergestelde hoek te slepen. De BBox kan verder worden bewerkt door over de randen van de BBox te bewegen en deze te verslepen, of door in het midden van de BBox te klikken en de hele box te verplaatsen. Het aanpassen van de positie en grootte van de BBox is ook mogelijk met behulp van het toetsenbord. Raadpleeg hiervoor de toetscombinaties die rechts van de foto worden weergegeven.\n",
    "\n",
    "Het toewijzen van klassen aan de BBox kan vooraf worden gedaan door het juiste label onder de foto aan te klikken (of met de overeenkomstige cijfertoetsen op het toetsenbord). Het aanpassen van de klassen na het maken van de BBox is ook mogelijk. Selecteer hiervoor het juiste label onder de foto, klik vervolgens op de naam die boven de BBox wordt weergegeven. Dit kan ook worden gedaan door op de BBox te klikken, het juiste label te selecteren en vervolgens op de toets <kbd>C</kbd> te drukken.\n",
    "\n",
    "Na het annoteren van de hele foto moeten de labels worden opgeslagen door op de knop <kbd>Submit</kbd> te drukken. Als in plaats daarvan op de knoppen <kbd>Back</kbd> of <kbd>Skip</kbd> wordt gedrukt, worden de labels niet opgeslagen en gaan de aanpassingen verloren. Wanneer de AI Assist is ingeschakeld, worden bij het tonen van een nieuwe foto direct annotaties weergegeven. Na controle van deze annotaties moeten ze (zelfs zonder aanpassingen) worden opgeslagen met <kbd>Submit</kbd> om de annotaties terug te kunnen vinden in de labelmap.\n",
    "\n",
    "**TIP: Tijdens het annoteren kom je ook foto's/segmenten tegen zonder objecten die je wilt herkennen. Sla deze segmenten toch op met <kbd>Submit</kbd> zodat je toekomstige model ook weet wat het niet hoeft te herkennen.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knoppen\n",
    "<kbd>Back</kbd><br>\n",
    "    Ga een foto terug. Annotaties worden niet opgeslagen.<br><br>\n",
    "<kbd>Skip</kbd><br>\n",
    "    Ga een foto vooruit. Annotaties worden niet opgeslagen.<br><br>\n",
    "<kbd>Submit</kbd><br>\n",
    "Ga een foto vooruit. Annotaties worden wel opgeslagen.<br><br>\n",
    "<kbd>Handmatig</kbd>/<kbd>AI gegenereerd</kbd><br>\n",
    "Bepaalt of het geselecteerde model wordt gebruikt om annotaties te genereren. Als deze functie is ingeschakeld, wordt in de voorspellingenmap gecontroleerd of er een annotatie is voor de betreffende foto en worden deze annotaties over de foto weergegeven. Als er nog geen voorspelling is voor de foto, wordt er direct een voorspelling gegenereerd. Als deze functie is uitgeschakeld, wordt gecontroleerd of er eerder handmatige annotaties zijn gemaakt en opgeslagen in de labelmap, en worden deze annotaties over de foto weergegeven. Als er nog geen annotaties zijn gemaakt, wordt de foto zonder annotatie weergegeven.<br><br>\n",
    "<kbd>Genereer annotaties</kbd><br>\n",
    "Verwijdert eerder gegenereerde labels uit de voorspellingenmap en genereert een nieuwe voorspelling. Dit heeft alleen effect als de weergegeven voorspelling niet overeenkomt met de foto (een onjuiste voorspelling) of wanneer een nieuw model wordt gebruikt dat mogelijk andere voorspellingen kan doen.<br><br>\n",
    "<kbd>Check Later</kbd><br>\n",
    "Maakt een kopie van het foto-/segmentbestand en slaat deze op in de \"check later\" map die je kunt vinden in je geselecteerde afbeeldingenmap. De labels voor deze foto worden niet verplaatst. Het doel van deze functie is het opslaan van foto's waar je onzeker over bent of momenteel niet aan wilt werken. Hierdoor kun je tijdens een groepsoverleg of op een ander moment de \"check later\" map selecteren tijdens het opstarten (met dezelfde labelmap) om deze foto's opnieuw te bekijken/bespreken.<br><br>\n",
    "<kbd>Delete image</kbd><br>\n",
    "Verwijdert het segment of de foto uit de afbeeldingenmap. Eventuele labels of kopieën in de \"check later\" map worden niet verwijderd.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69d15c5246c41bd8d626aad60493d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Model keuze</h3> Selecteer je project. Voorspellingen worden opgeslagen onder .…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Modules.ModelPicker import Launch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#Label widget moet naar externe file\n",
    "Launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data move** <code style=\"color:red;\">*Moet ik nog factchecken!!!*</code>\n",
    "De \"Data Move\" is een voorbereidende stap voor het trainen van een nieuw model. Het is bedoeld om de annotaties die gemaakt zijn te herordenen, zodat ze kunnen worden ingelezen tijdens het trainen. De tool kopieert of verplaatst (afhankelijk van de geselecteerde optie \"Copy\" of \"Move\") de foto's in de geselecteerde map die bijbehorende annotaties hebben naar de geselecteerde labelmap. De foto's worden verplaatst naar de \"Modeldata\" map in het geselecteerde project, waar ze worden opgeslagen onder de opgegeven modelnaam."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Bij het trainen van een nieuw model voor machine learning en beeldherkenning is het belangrijk om rekening te houden met concepten zoals overfitting, validatie- en testsets.\n",
    "\n",
    "Overfitting treedt op wanneer een model te specifiek wordt getraind op de beschikbare data en daardoor moeite heeft om goed te presteren op nieuwe, onbekende data. Dit gebeurt wanneer het model te veel aandacht besteedt aan de details en ruis in de trainingsdata, waardoor het niet goed kan generaliseren naar nieuwe voorbeelden. Een analogie hiervoor is bijvoorbeeld het studeren voor een Frans toets met flipkaartjes. Als je te veel studeert met de kaartjes, begin je de antwoorden te linken aan externe factoren, zoals een specifieke vouw in de hoek van het kaartje. Dit is echter niet nuttig tijdens de toets en leidt tot slechtere prestaties.\n",
    "\n",
    "Om overfitting te voorkomen, is het noodzakelijk om de beschikbare data op te splitsen in trainings-, validatie- en testsets. De trainingsset bestaat uit gelabelde voorbeelden die worden gebruikt om het model te trainen. Het is belangrijk om een voldoende grote en representatieve trainingsset te hebben, zodat het model patronen en kenmerken kan leren en generaliseren. Terugkomend op het voorbeeld van de Frans toets, de trainingsset bestaat uit de relevante theorie en voorbeelden die je gebruikt om te studeren. Als je niet genoeg trainingsdata hebt, loop je het risico dat je niet genoeg kennis en ervaring hebt om goed te presteren op de toets.\n",
    "\n",
    "De validatieset wordt gebruikt tijdens het trainingsproces om de prestaties van het model te meten en eventuele problemen zoals overfitting te detecteren. Het is een apart deel van de data dat niet wordt gebruikt om het model te trainen, maar om te evalueren hoe goed het model generaliseert naar nieuwe, ongeziene data. Hierdoor kun je aanpassingen maken aan het model en de trainingsparameters om de prestaties te verbeteren. Het percentage van de foto's dat moet worden gebruikt als validatieset moet meer dan 0% zijn. Terugkomend op het Frans toetsvoorbeeld, de validatieset kun je zien als een oefentoets die je maakt om te kijken of je het begrijpt. Als je te veel oefentoetsen maakt, besteed je mogelijk te weinig tijd aan het studeren, terwijl te weinig oefentoetsen je de kans ontneemt om moeilijke vragen te oefenen en te bepalen of je de stof echt beheerst.\n",
    "\n",
    "De testset is een aparte dataset die pas aan het einde van het trainingsproces wordt gebruikt om de uiteindelijke prestaties van het getrainde model te evalueren. Het is belangrijk om de testset niet te gebruiken tijdens het trainen of valideren, zodat de resultaten objectief blijven en de trainingsbeslissingen niet beïnvloeden. Terugkomend op het Frans toetsvoorbeeld, de testset is als de oefentoets die je docent de les vantevoren geeft om te oefenen voor de daadwerkelijke toets. Het is de laatste controle om te bepalen of je waarschijnlijk zult slagen of dat je nog een stukje hebt gemist en nog wat langer moet studeren. Het is een handig hulpmiddel om eventuele zwakke punten op te sporen, maar als je te vaak dezelfde oefentoetsen maakt, loop je het risico dat je eigenlijk aan het studeren bent voor de oefentoetsvragen en niet echt de taal leert.\n",
    "\n",
    "Door het gebruik van trainings-, validatie- en testsets kun je overfitting voorkomen, het model afstemmen en de prestaties objectief beoordelen. Hoewel in het gebruik van deze tool het mogelijk niet direct nodig is om een testset te specificeren, omdat je waarschijnlijk veel nieuwe modellen maakt met als enige onderscheid: meer data, is het nog steeds essentieel om een voldoende percentage van de foto's te reserveren als validatieset. YOLOv8 gebruikt deze data namelijk tijden het trainen en zal zonder deze data dan ook een error geven.\n",
    "\n",
    "Na het verplaatsen van de foto's en bijbehorende labels wordt er een configuratiebestand aangemaakt in de data map. Dit bestand geeft aan waar de data op het apparaat te vinden is en moet worden aangepast wanneer de data naar een nieuwe locatie op dezelfde of een andere computer wordt verplaatst. Dit bestand heb je nodig voor het instellen van het trainings process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1724c5fe0c464f43b1559ccb607a576a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>______________________________________________________________Data move________…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Modules.PreTrain import AnnotationMove\n",
    "\n",
    "AnnotationMove()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train** <code style=\"color:red;\">*Moet ik nog factchecken!!!*</code>\n",
    "\n",
    "Hier is de bijgewerkte tekst met de toevoegingen:\n",
    "\n",
    "Deze interface is bedoeld voor het trainen van een beeldherkenningsmodel. De interface heeft 3 tabbladen. Het eerste tabblad is bedoeld voor verder trainen met een bestaand model. Dit is handig wanneer je al een model hebt getraind, dit model hebt gebruikt om meer data te verzamelen, en nu een beter model wilt maken met dezelfde labels. Je kunt bijvoorbeeld de precisie en recall verbeteren of afwijkingen in de data corrigeren door nieuwe data toe te voegen zonder de afwijkingen.\n",
    "Het tweede tabblad is bedoeld voor het trainen van volledig nieuwe modellen. Dit is handig voor het eerste model dat wordt gemaakt tijdens een project of wanneer je extra labels aan een model wilt toevoegen.\n",
    "Het derde tabblad is bedoeld voor het voortzetten van een training, bijvoorbeeld wanneer je een training hebt gestart op je laptop maar deze niet was voltooid voordat je naar huis moest. In dit geval hoef je alleen maar het model te selecteren. Deze optie is niet mogelijk wanneer trainings- of validatiedata is verplaatst."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:red;\">*Disclaimer: Bij het trainen van een model zijn er meer instellingen beschikbaar dan die worden aangeboden in deze interface. Het doel van de interface is niet om het beste model te maken, maar om een snelle pijplijn te bieden voor het verzamelen, trainen en verbeteren van een model om het annotatieproces te versnellen.*</code>\n",
    "\n",
    "Tijdens het trainen vanaf de grond af aan of vanaf een ander model worden verschillende instellingen aangeboden. Hieronder volgt een beknopte uitleg van de betekenis en invloed van verschillende instellingen:\n",
    "\n",
    "* Modelkeuze:\n",
    "    * De keuze van het model heeft veel invloed wanneer je traint vanaf een bestaand model. Het geselecteerde model heeft al kennis van je labels en heeft ook al een keuze gemaakt voor een YOLO-model. Een model dat is gebaseerd op veel data heeft al een redelijk beeld en zal mogelijk minder effect zien van meer van dezelfde data, waardoor je misschien meer epochs moet doorlopen voordat je verbeteringen ziet. Het voordeel hiervan is echter dat het over het algemeen betere resultaten oplevert, omdat het model al een goed beeld heeft en alleen nog op nuances hoeft te letten.\n",
    "    * Bij het trainen van een compleet nieuw model heeft de modelkeuze vooral invloed op de trainingsduur en de maximale precisie en recall die je kunt behalen. Een kleiner model zorgt voor een snellere training en snellere voorspellingen na het trainen. YOLO biedt modellen aan in verschillende maten, variërend van nano tot Xtra large, waarbij nano het snelste en lichtste model is, en Xtra large het grootste en meest complexe model. Het is aan te raden om klein te beginnen en als je merkt dat de resultaten na het trainen met voldoende data niet hoog genoeg zijn, kun je experimenteren met grotere modellen. Houd er echter rekening mee dat grotere modellen zowel tijdens het trainen als tijdens het gebruik meer computerbronnen vereisen en mogelijk langere verwerkingstijden hebben.\n",
    "* Configuration file\n",
    "    * Dit bestand geeft aan waar je foto's en labels zich bevinden en welke labels zijn gebruikt tijdens het annotatieproces. Het configuratiebestand wordt aangemaakt bij het verplaatsen van de data met behulp van de \"Data Move\", zoals hierboven beschreven, en hoeft verder niet aangepast te worden, tenzij je de mappen met data verplaatst.\n",
    "* Project\n",
    "    * Hier geef je aan waar je het nieuwe model wilt opslaan. Het trainingsproces maakt een map aan waarin aan het einde van de training grafieken worden gegenereerd die de trainingsvoortgang en de prestaties van het nieuwe model weergeven. Binnen het geselecteerde project wordt ook een map voor modellen aangemaakt, waarin de nieuwe modellen worden gekopieerd en omgezet naar een .onnx-model (.pt voor training en .onnx voor snellere voorspellingen op de CPU). Het geselecteerde project hoeft niet hetzelfde te zijn als het project waarin je data is opgeslagen.\n",
    "* Model naam\n",
    "    * Hiermee geef je aan hoe de map met de hierboven genoemde grafieken wordt genoemd en hoe de modellen worden benoemd.\n",
    "* Nummer of epochs:\n",
    "    * Het aantal epochs geeft aan hoe vaak je het model over de gehele dataset wilt laten trainen. Meer epochs betekenen over het algemeen betere resultaten, maar te veel epochs kunnen leiden tot overfitting. Het juiste aantal epochs hangt onder andere af van de complexiteit van je data, de hoeveelheid data, het aantal klassen dat je hebt en de grootte van je batch. Dit is een waarde die je alleen kunt vinden door te experimenteren. Op basis van de hoeveelheid data kun je een ruwe schatting maken en je model trainen. Daarna kun je naar de geproduceerde grafieken kijken, zoals de loss-factoren. Over het algemeen wil je zien dat de grafiek afvlakt en niet verder stijgt. Voor meer informatie kun je zoeken naar 'object detection loss' en 'overfitting'.\n",
    "* Batchgrootte:\n",
    "    * De batchgrootte geeft aan hoeveel foto's of segmenten het model tegelijkertijd bekijkt tijdens het trainen. Hoe hoog deze waarde kan zijn, hangt af van de beschikbare geheugenruimte en de omvang van je data. Dit is een waarde die ook moet worden getest en geoptimaliseerd. Probeer de batchgrootte zo groot mogelijk in te stellen zonder dat de training crasht vanwege geheugenproblemen. Over het algemeen zorgt een grotere batchgrootte voor een beter model in minder stappen. Als de loss-grafiek na het trainen grote pieken en dalen vertoont in plaats van een redelijk constante lijn, kan dit een indicatie zijn van een te kleine batchgrootte, wat de prestaties van het model permanent kan belemmeren.\n",
    "* Foto size\n",
    "    * Hiermee geef je aan hoe groot je segmenten (images) zijn. Over het algemeen wordt aanbevolen om deze waarde gelijk te houden aan de grootte van je segmenten. Het is echter ook mogelijk om deze waarde hoger of lager te maken (waarbij YOLO de resolutie van de foto aanpast). Het voordeel hiervan kan zijn dat de belasting van je computer wordt verminderd en de batchgrootte kan worden verhoogd. Houd er echter rekening mee dat je hiermee ook scherpte en detail in je foto's verliest, dus gebruik deze optie met mate. Foto's met andere afmetingen worden passend gemaakt binnen de opgegeven vierkante afmetingen door extra zwarte randen boven of links van de foto te plaatsen om de 1:1-verhouding te behouden.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1f620e28d548799ce525afe76cad22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='selecteer het <b>model.pt (NIET .ONNX)</b> waarvan het nieuwe model k…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Modules.ModelTrain import train\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Well-Anotate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
